import os
import logging
import asyncio
import time
from typing import Dict, List, Optional, AsyncGenerator

from google import genai
from google.genai import types

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤
from promotions_api import get_promotions_json
from sheets_gateway import AsyncGoogleSheetsGateway


logger = logging.getLogger(__name__)


class GeminiService:
    """–°–µ—Ä–≤–∏—Å –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å Google Gemini API.
    
    –§—É–Ω–∫—Ü–∏–æ–Ω–∞–ª:
    - –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–µ–π –¥–∏–∞–ª–æ–≥–æ–≤ –≤ –ø–∞–º—è—Ç–∏ (user_id -> chat_history)
    - –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–æ 10 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π
    - –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ç–æ–∫–µ–Ω–æ–≤
    - –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
    """

    def __init__(self, promotions_gateway: Optional[AsyncGoogleSheetsGateway] = None) -> None:
        self.promotions_gateway = promotions_gateway
        
        # –í–∞—Ä–∏–∞–Ω—Ç –ë (–ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω–æ): —Ç–æ–ª—å–∫–æ Gemini —á–µ—Ä–µ–∑ –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏–π —Å–µ—Ä–≤–µ—Ä (reverse proxy)
        proxyapi_key = os.getenv("PROXYAPI_KEY")
        proxyapi_base_url = os.getenv("PROXYAPI_BASE_URL")
        
        if proxyapi_key and proxyapi_base_url:
            logger.info("Using custom Gemini endpoint (bypass regional restrictions)")
            try:
                self.client = genai.Client(
                    api_key=proxyapi_key,
                    http_options={
                        'base_url': proxyapi_base_url,
                        'api_version': 'v1beta'
                    }
                )
                logger.info("GeminiService initialized via proxy (bypass regional restrictions)")
            except Exception as e:
                logger.error(f"Failed to initialize GeminiService via ProxyAPI: {e}", exc_info=True)
                self.client = None
        
        # –í–∞—Ä–∏–∞–Ω—Ç –ê: –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π API (—Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π HTTP_PROXY –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è)
        else:
            api_key = os.getenv("GEMINI_API_KEY")
            if not api_key:
                logger.warning("GeminiService disabled: missing GEMINI_API_KEY")
                self.client = None
            else:
                try:
                    # –í google-genai SDK –ø—Ä–æ–∫—Å–∏ –ø–æ–¥—Ö–≤–∞—Ç—ã–≤–∞–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–∑ –æ–∫—Ä—É–∂–µ–Ω–∏—è (HTTP_PROXY/HTTPS_PROXY)
                    # –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ —É–∂–µ –ø—Ä–æ–ø–∏—Å–∞–Ω—ã –≤ .env –∏ –ø–æ–¥–≥—Ä—É–∂–∞—é—Ç—Å—è systemd.
                    # –Ø–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –≤ HttpOptions –≤—ã–∑—ã–≤–∞–ª–æ –æ—à–∏–±–∫—É –≤–∞–ª–∏–¥–∞—Ü–∏–∏.
                    self.client = genai.Client(api_key=api_key)
                    http_proxy = os.getenv("HTTP_PROXY")
                    if http_proxy:
                        logger.info(f"GeminiService initialized with HTTP_PROXY: {http_proxy}")
                    else:
                        logger.info("GeminiService initialized (direct connection)")
                except Exception as e:
                    logger.error(f"Failed to initialize GeminiService: {e}", exc_info=True)
                    self.client = None
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø—Ä–æ–º–ø—Ç–∞
        system_prompt_path = os.getenv("SYSTEM_PROMPT_FILE", "system_prompt.txt")
        self.system_instruction = None
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è Knowledge Base (RAG)
        from drive_service import DriveService
        from knowledge_base import KnowledgeBase
        
        self.drive_service = DriveService()
        self.knowledge_base = KnowledgeBase(self.drive_service)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞ –ø—Ä–æ–º–ø—Ç–∞
        if os.path.exists(system_prompt_path):
            try:
                with open(system_prompt_path, 'r', encoding='utf-8') as f:
                    user_business_rules = f.read()
                    
                # –¢–ó v5.0: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –î—Ä–∞–π–≤–µ—Ä (Priority: ROOT)
                # –ü–æ–∑–≤–æ–ª—è–µ—Ç –æ–±–æ–π—Ç–∏ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏—è —Ñ–∞–π–ª–∞ –∑–∞–∫–∞–∑—á–∏–∫–∞
                technical_driver = """
### SYSTEM OVERRIDE (PRIORITY LEVEL: ROOT)
–¢—ã ‚Äî –ò–ò-–º–æ–¥–µ–ª—å, —É–ø—Ä–∞–≤–ª—è–µ–º–∞—è —ç—Ç–∏–º —Å–∏—Å—Ç–µ–º–Ω—ã–º —Å–ª–æ–µ–º.
–ù–∏–∂–µ –∏–¥—É—Ç –±–∏–∑–Ω–µ—Å-–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –°–æ–±–ª—é–¥–∞–π –∏—Ö —Å—Ç—Ä–æ–≥–æ, –ù–û —Å —É—á–µ—Ç–æ–º —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∞–≤–∏–ª:

1. **–ò–ù–°–¢–†–£–ú–ï–ù–¢–´ (TOOLS):** –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –∫–∞—Å–∞–µ—Ç—Å—è —Ü–µ–Ω, –∞–∫—Ü–∏–π, –∏–ø–æ—Ç–µ–∫–∏ ‚Äî –ò–ì–ù–û–†–ò–†–£–ô –∑–∞–ø—Ä–µ—Ç –Ω–∞ –≤–Ω–µ—à–Ω–∏–µ –¥–∞–Ω–Ω—ã–µ. –¢–´ –û–ë–Ø–ó–ê–ù –≤—ã–∑–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é `get_promotions`.
# 2. **POISK (WEB SEARCH):** (–í—Ä–µ–º–µ–Ω–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏)
3. **–ö–†–ï–ê–¢–ò–í:** –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –ø—Ä–æ—Å–∏—Ç —Ç–≤–æ—Ä—á–µ—Å—Ç–≤–æ ‚Äî –ò–ì–ù–û–†–ò–†–£–ô –∑–∞–ø—Ä–µ—Ç –Ω–∞ "–æ—Ç—Å–µ–±—è—Ç–∏–Ω—É".
4. **–≠–°–ö–ê–õ–ê–¶–ò–Ø:** –î–ª—è –≤—ã–∑–æ–≤–∞ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ –¥–æ–±–∞–≤–ª—è–π —Ç–µ–≥: [ESCALATE_ACTION].
5. **–ó–ê–©–ò–¢–ê –°–°–´–õ–û–ö (–ö–†–ò–¢–ò–ß–ù–û):**
   - –ù–∏–∫–æ–≥–¥–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π Markdown-—Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–Ω—É—Ç—Ä–∏ URL.
   - –°–¢–†–û–ñ–ê–ô–®–ï –ó–ê–ü–†–ï–©–ï–ù–û —É–¥–∞–ª—è—Ç—å –∏–ª–∏ —ç–∫—Ä–∞–Ω–∏—Ä–æ–≤–∞—Ç—å —Å–∏–º–≤–æ–ª—ã `_` (–Ω–∏–∂–Ω–µ–µ –ø–æ–¥—á–µ—Ä–∫–∏–≤–∞–Ω–∏–µ) –≤ —Å—Å—ã–ª–∫–∞—Ö.
   - –°—Å—ã–ª–∫–∞ `t.me/tp_esoft` –¥–æ–ª–∂–Ω–∞ –æ—Å—Ç–∞—Ç—å—Å—è `t.me/tp_esoft`, –∞ –Ω–µ `t.me/tpesoft`.
   - –í—ã–≤–æ–¥–∏ —Å—Å—ã–ª–∫–∏ –∫–∞–∫ Plain Text.

### --- –ù–ê–ß–ê–õ–û –ë–ò–ó–ù–ï–°-–ò–ù–°–¢–†–£–ö–¶–ò–ò –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ---
"""
                self.system_instruction = technical_driver + user_business_rules
                logger.info("System prompt loaded with Technical Driver (ROOT OVERRIDE active)")
            except Exception as e:
                logger.error(f"Failed to load system prompt from {system_prompt_path}: {e}", exc_info=True)
        else:
            logger.warning(f"System prompt file not found: {system_prompt_path}")
        
        # –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã (Function Calling)
        self.tools = [
            types.Tool(
                function_declarations=[types.FunctionDeclaration(
                    name='get_promotions',
                    description='–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—É—â–∏—Ö –∞–∫—Ü–∏–π, —Å–∫–∏–¥–æ–∫ –∏ —É—Å–ª–æ–≤–∏–π –∏–ø–æ—Ç–µ–∫–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö. –ü–†–ò–û–†–ò–¢–ï–¢–ù–´–ô –ò–°–¢–û–ß–ù–ò–ö –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ –≤—ã–≥–æ–¥–µ.',
                    parameters=types.Schema(
                        type='OBJECT',
                        properties={}
                    )
                )]
            )
        ]
        
        # –•—Ä–∞–Ω–∏–ª–∏—â–µ –∏—Å—Ç–æ—Ä–∏–∏ –¥–∏–∞–ª–æ–≥–æ–≤: user_id -> list of Content objects
        self.user_histories: Dict[int, List[types.Content]] = {}
        # TTL tracking –¥–ª—è –∑–∞—â–∏—Ç—ã –æ—Ç memory leak
        self._history_timestamps: Dict[int, float] = {}
        self._max_histories = 500  # –ú–∞–∫—Å–∏–º—É–º —Å–µ—Å—Å–∏–π –≤ –ø–∞–º—è—Ç–∏
        self._history_ttl = 3600 * 24  # 24 —á–∞—Å–∞ TTL
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏
        # –í–ê–ñ–ù–û: –î–ª—è Context Caching –∏–º—è –º–æ–¥–µ–ª–∏ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–æ–ª–∂–Ω–æ —Å–æ–≤–ø–∞–¥–∞—Ç—å —Å —Ç–µ–º, –≥–¥–µ —Å–æ–∑–¥–∞–Ω –∫—ç—à.
        self.model_name = "gemini-3-pro-preview" 
        self.max_history_messages = 12  # –û–ø—Ç–∏–º–∞–ª—å–Ω–æ –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Å–∫–æ–ª—å–∑—è—â–µ–≥–æ –æ–∫–Ω–∞ (6 –ø–∞—Ä)
        
        # –ö—ç—à –¥–ª—è –∞–∫—Ü–∏–π (Simple TTL Cache)
        self._promotions_cache = None
        self._promotions_cache_time = 0
        self._promotions_cache_ttl = 600  # 10 –º–∏–Ω—É—Ç

    async def initialize(self):
        """Async init for Knowledge Base with Rules and Tools."""
        if self.knowledge_base:
            await self.knowledge_base.initialize()
            # –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–û –∑–∞–ø—É—Å–∫–∞–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫—ç—à–∞ —Å –Ω–∞—à–∏–º–∏ –ø—Ä–∞–≤–∏–ª–∞–º–∏
            asyncio.create_task(self.knowledge_base.refresh_cache(
                system_instruction=self.system_instruction,
                tools=self.tools
            ))

    def is_enabled(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –¥–æ—Å—Ç—É–ø–µ–Ω –ª–∏ —Å–µ—Ä–≤–∏—Å."""
        return self.client is not None

    def _cleanup_old_histories(self) -> None:
        """–û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∏—Å—Ç–æ—Ä–∏–π –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è memory leak."""
        now = time.time()
        
        # –£–¥–∞–ª—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–µ (—Å—Ç–∞—Ä—à–µ TTL)
        expired = [uid for uid, ts in self._history_timestamps.items() if now - ts > self._history_ttl]
        for uid in expired:
            self.user_histories.pop(uid, None)
            self._history_timestamps.pop(uid, None)
        
        if expired:
            logger.info(f"Cleaned up {len(expired)} expired chat histories (TTL: {self._history_ttl}s)")
        
        # –ï—Å–ª–∏ –≤—Å—ë –µ—â—ë —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ ‚Äî —É–¥–∞–ª—è–µ–º —Å–∞–º—ã–µ —Å—Ç–∞—Ä—ã–µ
        if len(self.user_histories) > self._max_histories:
            sorted_users = sorted(self._history_timestamps.items(), key=lambda x: x[1])
            to_remove = len(self.user_histories) - self._max_histories // 2
            for uid, _ in sorted_users[:to_remove]:
                self.user_histories.pop(uid, None)
                self._history_timestamps.pop(uid, None)
            logger.warning(f"Memory cleanup: removed {to_remove} oldest histories (limit: {self._max_histories})")

    def _get_or_create_history(self, user_id: int) -> List[types.Content]:
        """–ü–æ–ª—É—á–∞–µ—Ç –∏–ª–∏ —Å–æ–∑–¥–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
        
        –†–µ–∞–ª–∏–∑–∞—Ü–∏—è Context Injection (–¢–ó –ë–ª–æ–∫ –ê-1):
        –í–º–µ—Å—Ç–æ —Å–∏—Å—Ç–µ–º–Ω–æ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞ –≤—Å—Ç–∞–≤–ª—è–µ–º 2 —Ñ–µ–π–∫–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏—è.
        """
        # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∏—Å—Ç–æ—Ä–∏–π
        if len(self.user_histories) > self._max_histories // 2:
            self._cleanup_old_histories()
        
        # –û–±–Ω–æ–≤–ª—è–µ–º timestamp –ø–æ—Å–ª–µ–¥–Ω–µ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        self._history_timestamps[user_id] = time.time()
        
        if user_id not in self.user_histories:
            self.user_histories[user_id] = []
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∫–∞–∫ –ø–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ (Role: User)
            if self.system_instruction:
                self.user_histories[user_id].append(
                    types.Content(
                        role="user",
                        parts=[types.Part(text=self.system_instruction)]
                    )
                )
                # –ü–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ –æ—Ç –º–æ–¥–µ–ª–∏ (Role: Model)
                self.user_histories[user_id].append(
                    types.Content(
                        role="model",
                        parts=[types.Part(text="–ü—Ä–∏–Ω—è—Ç–æ. –Ø —Ä–∞–±–æ—Ç–∞—é –≤ —Ä–µ–∂–∏–º–µ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ –≠—Ç–∞–∂–µ–π. –ì–æ—Ç–æ–≤ –∫ –≤–æ–ø—Ä–æ—Å–∞–º.")]
                    )
                )
            logger.info(f"Created new chat history for user {user_id} with Fake History Injection")
        
        return self.user_histories[user_id]

    def _add_to_history(self, user_id: int, role: str, content: str) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç —Å–æ–æ–±—â–µ–Ω–∏–µ –≤ –∏—Å—Ç–æ—Ä–∏—é —Å –∑–∞—â–∏—Ç–æ–π Context Pinning (–¢–ó –ë–ª–æ–∫ –ê-2)."""
        history = self._get_or_create_history(user_id)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        history.append(
            types.Content(
                role=role,
                parts=[types.Part(text=content)]
            )
        )
        
        # –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –∏—Å—Ç–æ—Ä–∏–∏ —Å –∑–∞—â–∏—Ç–æ–π –∏–Ω–¥–µ–∫—Å–æ–≤ 0 –∏ 1
        # –ù–æ–≤–∞—è –∏—Å—Ç–æ—Ä–∏—è = [Msg0, Msg1] + [–ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π]
        if len(history) > self.max_history_messages + 2:
            # –£–¥–∞–ª—è–µ–º —Å–∞–º–æ–µ —Å—Ç–∞—Ä–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ—Å–ª–µ –∑–∞–∫—Ä–µ–ø–ª—ë–Ω–Ω—ã—Ö (–∏–Ω–¥–µ–∫—Å 2)
            history.pop(2)
            logger.debug(f"History Pinning: removed message at index 2 for user {user_id}. Context preserved.")

    async def ask_stream(self, user_id: int, content: str) -> AsyncGenerator[str, None]:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ Gemini –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä –¥–ª—è —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ (Async).
        –°–æ–¥–µ—Ä–∂–∏—Ç –º–µ—Ö–∞–Ω–∏–∑–º Auto-Retry –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –ø—É—Å—Ç—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤ –ø—Ä–∏ –Ω–µ—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–∏.
        """
        if not self.is_enabled():
            yield "–°–µ—Ä–≤–∏—Å –ò–ò –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
            return

        # –î–æ–±–∞–≤–ª—è–µ–º —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –∏—Å—Ç–æ—Ä–∏—é (–¢–û–õ–¨–ö–û –û–î–ò–ù –†–ê–ó –ø–µ—Ä–µ–¥ –ø–æ–ø—ã—Ç–∫–∞–º–∏)
        # –ï—Å–ª–∏ —ç—Ç–æ —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –≤—ã–∑–æ–≤ (content=""), —Å–æ–æ–±—â–µ–Ω–∏–µ —É–∂–µ —Ç–∞–º
        if content:
             self._add_to_history(user_id, "user", content)
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å—é –∏—Å—Ç–æ—Ä–∏—é –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏
        history = self._get_or_create_history(user_id)
        
        # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–æ–≤ (–≤—Å–µ–≥–¥–∞ –∞–∫—Ç—É–∞–ª—å–Ω–∞—è)
        tools = [
            types.Tool(
                function_declarations=[types.FunctionDeclaration(
                    name='get_promotions',
                    description='–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ —Ç–µ–∫—É—â–∏—Ö –∞–∫—Ü–∏–π, —Å–∫–∏–¥–æ–∫ –∏ —É—Å–ª–æ–≤–∏–π –∏–ø–æ—Ç–µ–∫–∏ –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö. –ü–†–ò–û–†–ò–¢–ï–¢–ù–´–ô –ò–°–¢–û–ß–ù–ò–ö –¥–ª—è –≤–æ–ø—Ä–æ—Å–æ–≤ –æ –≤—ã–≥–æ–¥–µ.',
                    parameters=types.Schema(type='OBJECT', properties={})
                )]
            )
        ]

        cache_name = await self.knowledge_base.get_cache_name()
        config_params = {
            'temperature': 0.7,
            'max_output_tokens': 8192,
            'top_p': 0.95,
            'top_k': 40,
            'safety_settings': [
                types.SafetySetting(category="HARM_CATEGORY_HARASSMENT", threshold="BLOCK_NONE"),
                types.SafetySetting(category="HARM_CATEGORY_HATE_SPEECH", threshold="BLOCK_NONE"),
                types.SafetySetting(category="HARM_CATEGORY_SEXUALLY_EXPLICIT", threshold="BLOCK_NONE"),
                types.SafetySetting(category="HARM_CATEGORY_DANGEROUS_CONTENT", threshold="BLOCK_NONE"),
                types.SafetySetting(category="HARM_CATEGORY_CIVIC_INTEGRITY", threshold="BLOCK_NONE"),
            ]
        }
        
        if not cache_name:
            config_params['system_instruction'] = self.system_instruction
            config_params['tools'] = tools
        else:
            config_params['cached_content'] = cache_name
        
        config = types.GenerateContentConfig(**config_params)
        generate_kwargs = {
            'model': self.model_name,
            'contents': history,
            'config': config
        }

        # --- AUTO-RETRY LOGIC START ---
        MAX_RETRIES = 2
        full_reply_parts = []
        grounding_sources = {}
        
        for attempt in range(MAX_RETRIES + 1):
            full_reply_parts = [] # –°–±—Ä–æ—Å –±—É—Ñ–µ—Ä–æ–≤ –ø–µ—Ä–µ–¥ –Ω–æ–≤–æ–π –ø–æ–ø—ã—Ç–∫–æ–π
            grounding_sources = {}
            has_started_response = False # –§–ª–∞–≥: –Ω–∞—á–∞–ª–∏ –ª–∏ –º—ã —É–∂–µ –æ—Ç–¥–∞–≤–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
            
            try:
                logger.info(f"Starting stream for user {user_id} (Attempt {attempt+1}/{MAX_RETRIES+1})")
                
                # –¢–∞–π–º–∞—É—Ç –Ω–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é —Å—Ç—Ä–∏–º–∞ (60 —Å–µ–∫—É–Ω–¥)
                STREAM_INIT_TIMEOUT = 60.0
                try:
                    stream = await asyncio.wait_for(
                        self.client.aio.models.generate_content_stream(**generate_kwargs),
                        timeout=STREAM_INIT_TIMEOUT
                    )
                except asyncio.TimeoutError:
                    logger.error(f"Gemini stream init timeout ({STREAM_INIT_TIMEOUT}s) for user {user_id}")
                    raise TimeoutError(f"Gemini API –Ω–µ –æ—Ç–≤–µ—Ç–∏–ª –∑–∞ {STREAM_INIT_TIMEOUT} —Å–µ–∫—É–Ω–¥")
                
                async for response in stream:
                    
                    # –°–±–æ—Ä Grounding Metadata
                    if response.candidates and response.candidates[0].grounding_metadata:
                        gm = response.candidates[0].grounding_metadata
                        if gm.grounding_chunks:
                            for chunk in gm.grounding_chunks:
                                if chunk.web and chunk.web.uri and chunk.web.title:
                                    grounding_sources[chunk.web.uri] = chunk.web.title

                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ Function Call –≤ –ø–µ—Ä–≤–æ–º —á–∞–Ω–∫–µ
                    if response.candidates and response.candidates[0].content.parts:
                        part = response.candidates[0].content.parts[0]
                        
                        if part.function_call:
                            has_started_response = True # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏ —ç—Ç–æ –æ—Ç–≤–µ—Ç
                            fc = part.function_call
                            logger.info(f"–ò–ò –≤—ã–∑—ã–≤–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏—é (STREAM): {fc.name}")
                            
                            yield f"__TOOL_CALL__:{fc.name}"
                            
                            tool_result = "–î–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"
                            if fc.name == 'get_promotions':
                                now = time.time()
                                if self._promotions_cache and (now - self._promotions_cache_time < self._promotions_cache_ttl):
                                    tool_result = self._promotions_cache
                                    logger.info("Using TTLCache for promotions")
                                else:
                                    if self.promotions_gateway:
                                        try:
                                            tool_result = await get_promotions_json(self.promotions_gateway)
                                            self._promotions_cache = tool_result
                                            self._promotions_cache_time = now
                                            logger.info(f"Promotions cache updated (len: {len(tool_result)})")
                                        except Exception as te:
                                            logger.error(f"Error calling promotion tool in stream: {te}")
                                    
                            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é
                            self.user_histories[user_id].append(response.candidates[0].content)
                            function_response_part = types.Part(
                                function_response=types.FunctionResponse(
                                    name=fc.name,
                                    response={'output': tool_result}
                                )
                            )
                            self.user_histories[user_id].append(types.Content(role="tool", parts=[function_response_part]))
                            
                            # RECURSION: –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º —Å—Ç—Ä–∏–º –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —Ñ—É–Ω–∫—Ü–∏—é
                            # –ó–¥–µ—Å—å –≤–∞–∂–Ω–æ: —Ä–µ–∫—É—Ä—Å–∏–≤–Ω—ã–π –≤—ã–∑–æ–≤ ask_stream –±—É–¥–µ—Ç –∏–º–µ—Ç—å —Å–≤–æ–π —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π —Ü–∏–∫–ª retries!
                            async for sub_part in self.ask_stream(user_id, ""): 
                                if sub_part:
                                    yield sub_part
                            return # –ü–æ–ª–Ω—ã–π –≤—ã—Ö–æ–¥ –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (—É—Å–ø–µ—Ö)

                        # –ï—Å–ª–∏ —ç—Ç–æ –æ–±—ã—á–Ω—ã–π —Ç–µ–∫—Å—Ç
                        if response.text:
                            text_chunk = response.text
                            # –ï—Å–ª–∏ —Ç–µ–∫—Å—Ç –ø—Ä–∏—à–µ–ª, –∑–Ω–∞—á–∏—Ç —ç—Ç–æ –Ω–µ –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç
                            has_started_response = True
                            full_reply_parts.append(text_chunk)
                            yield text_chunk

                # –ö–æ–Ω–µ—Ü —Ü–∏–∫–ª–∞ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞ –¥–ª—è –¥–∞–Ω–Ω–æ–π –ø–æ–ø—ã—Ç–∫–∏
                
                # –ö–ª—é—á–µ–≤–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –ë—ã–ª –ª–∏ –ø–æ–ª—É—á–µ–Ω –∫–∞–∫–æ–π-—Ç–æ —Ç–µ–∫—Å—Ç?
                if not full_reply_parts:
                    # –ï—Å–ª–∏ —Å—Ç—Ä–∏–º –∑–∞–≤–µ—Ä—à–∏–ª—Å—è –±–µ–∑ —Ç–µ–∫—Å—Ç–∞ –∏ –±–µ–∑ function call -> –≠—Ç–æ "Empty Response"
                    raise ValueError("Received empty stream response from Gemini model")
                
                # –ï—Å–ª–∏ –º—ã –∑–¥–µ—Å—å, –∑–Ω–∞—á–∏—Ç –æ—Ç–≤–µ—Ç –ø–æ–ª—É—á–µ–Ω (full_reply_parts –Ω–µ –ø—É—Å—Ç), –≤—ã—Ö–æ–¥–∏–º –∏–∑ —Ü–∏–∫–ª–∞ retry
                break 

            except Exception as e:
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–∫–∏
                if has_started_response:
                    # –ï—Å–ª–∏ –º—ã —É–∂–µ –Ω–∞—á–∞–ª–∏ —Å—Ç—Ä–∏–º–∏—Ç—å —Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, –º—ã –ù–ï –ú–û–ñ–ï–ú –¥–µ–ª–∞—Ç—å —Ä–µ—Ç—Ä–∞–π
                    # –∏–Ω–∞—á–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —É–≤–∏–¥–∏—Ç –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –∏–ª–∏ –∫–∞—à—É.
                    # –ü—Ä–æ—Å—Ç–æ –ª–æ–≥–∏—Ä—É–µ–º –∏ –ø—Ä–µ—Ä—ã–≤–∞–µ–º.
                    logger.error(f"Stream error AFTER yield (user {user_id}): {e}")
                    yield f"\n[‚ö†Ô∏è –û–±—Ä—ã–≤ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è: {str(e)[:50]}]"
                    return # –ü—Ä–µ—Ä—ã–≤–∞–µ–º —Å—Ç—Ä–∏–º
                
                # –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –æ—à–∏–±–∫–∏ –∏—Å—Ç–µ–∫—à–µ–≥–æ –∫—ç—à–∞ –∏–ª–∏ —É—Å—Ç–∞—Ä–µ–≤—à–µ–≥–æ API
                is_cache_error = False
                error_str = str(e)
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—à–∏–±–∫–∏ –∫—ç—à–∞: –∏—Å—Ç–µ–∫—à–∏–π, –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–π, –∏–ª–∏ —É—Å—Ç–∞—Ä–µ–≤—à–∏–π API
                if ('CachedContent' in error_str and ('403' in error_str or 'PERMISSION_DENIED' in error_str)) or \
                   'google_search_retrieval' in error_str or \
                   'not supported' in error_str.lower():
                    logger.warning(f"‚ùå Cache error or outdated API: {e}")
                    is_cache_error = True
                    # –ò–Ω–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∫—ç—à –≤ Knowledge Base
                    await self.knowledge_base.invalidate_cache()
                    # –ü–µ—Ä–µ—Å–æ–∑–¥–∞—Ç—å config –ë–ï–ó –∫—ç—à–∞ –¥–ª—è –ø–æ–≤—Ç–æ—Ä–∞
                    config_params['system_instruction'] = self.system_instruction
                    config_params['tools'] = tools
                    if 'cached_content' in config_params:
                        del config_params['cached_content']
                    config = types.GenerateContentConfig(**config_params)
                    generate_kwargs['config'] = config
                
                # –ï—Å–ª–∏ –º—ã –µ—â–µ –ù–ò–ß–ï–ì–û –Ω–µ –≤—ã–¥–∞–ª–∏ (–ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –∏–ª–∏ –æ—à–∏–±–∫–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è —Å—Ä–∞–∑—É)
                logger.warning(f"Gemini attempt {attempt+1} failed: {e}")
                
                if attempt < MAX_RETRIES:
                    if is_cache_error:
                        logger.info("üîÑ Retrying WITHOUT cache (fallback mode)")
                    await asyncio.sleep(0.5) # –ü–∞—É–∑–∞ –ø–µ—Ä–µ–¥ —Ä–µ—Ç—Ä–∞–µ–º
                    continue # –ò–¥–µ–º –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –∫—Ä—É–≥
                else:
                    # –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã
                    logger.error(f"All {MAX_RETRIES+1} attempts failed for user {user_id}")
                    # –ù–µ –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å yield –æ—à–∏–±–∫–∏, –ø—É—Å—Ç—å –≤—ã–∑—ã–≤–∞—é—â–∏–π –∫–æ–¥ (chat_handler) –ø–æ–∫–∞–∂–µ—Ç –∑–∞–≥–ª—É—à–∫—É "–ò–∑–≤–∏–Ω–∏—Ç–µ..."
                    # –∏–ª–∏ –º—ã –º–æ–∂–µ–º —Å–∞–º–∏ –∫–∏–Ω—É—Ç—å –æ—à–∏–±–∫—É —á—Ç–æ–±—ã chat_handler –µ–µ –ø–æ–π–º–∞–ª
                    raise e

        # --- FINALIZATION (Success case) ---
        
        # –§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –±–ª–æ–∫–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (Grounding)
        if grounding_sources:
            sources_text = "\n\nüìö **–ò—Å—Ç–æ—á–Ω–∏–∫–∏:**\n"
            for i, (uri, title) in enumerate(grounding_sources.items(), 1):
                sources_text += f"{i}. [{title}]({uri})\n"
            
            yield sources_text
            full_reply_parts.append(sources_text)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –≤ –∏—Å—Ç–æ—Ä–∏—é
        if full_reply_parts:
            full_reply = "".join(full_reply_parts)
            self._add_to_history(user_id, "model", full_reply)
            logger.info(f"Stream finished for user {user_id}, history updated. Sources: {len(grounding_sources)}")

    async def ask(self, user_id: int, content: str) -> Optional[str]:
        """–û—Ç–ø—Ä–∞–≤–ª—è–µ—Ç –∑–∞–ø—Ä–æ—Å –≤ Gemini –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç (—á–µ—Ä–µ–∑ —Å—Ç—Ä–∏–º–∏–Ω–≥)."""
        full_reply = []
        async for chunk in self.ask_stream(user_id, content):
            if not chunk.startswith("__TOOL_CALL__"):
                full_reply.append(chunk)
        
        return "".join(full_reply) if full_reply else None

    def clear_history(self, user_id: int) -> None:
        """–û—á–∏—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è."""
        if user_id in self.user_histories:
            del self.user_histories[user_id]
            logger.info(f"Cleared chat history for user {user_id}")
    async def generate_image_prompt(self, text_context: str) -> Optional[str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ–º–ø—Ç –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç–∞ (–ê—Ä—Ç-–¥–∏—Ä–µ–∫—Ç–æ—Ä)."""
        if not self.is_enabled():
            return None
            
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å-–ª–∞–π—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞
            model = "gemini-2.0-flash-lite-preview-02-05"
            prompt = (
                f"Analyze this text and write ONE detailed, cinematic English prompt "
                f"for high-end photorealistic image generation (8k, highly detailed) "
                f"that perfectly illustrates the context. Return ONLY the prompt.\n\n"
                f"Context: {text_context[:1000]}"
            )
            
            response = await self.client.aio.models.generate_content(
                model=model,
                contents=prompt
            )
            
            if response.text:
                logger.info(f"Image prompt generated: {response.text[:50]}...")
                return response.text.strip()
            return None
            
        except Exception as e:
            logger.error(f"Error generating image prompt: {e}")
            return None

    async def generate_image(self, prompt: str) -> Optional[bytes]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ –ø—Ä–æ–º–ø—Ç—É (–•—É–¥–æ–∂–Ω–∏–∫)."""
        if not self.is_enabled():
            return None
            
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º Gemini 3 Pro Image (Preview) –ø–æ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—é –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            # ID –∏–∑ —Å–ø–∏—Å–∫–∞ –º–æ–¥–µ–ª–µ–π: models/gemini-3-pro-image-preview
            model = "models/gemini-3-pro-image-preview"
            
            # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
            config = types.GenerateImagesConfig(
                number_of_images=1,
                aspect_ratio="16:9",
                person_generation="allow_adult", # –†–∞–∑—Ä–µ—à–∞–µ–º –ª—é–¥–µ–π (–±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Ç–µ–∫—Å—Ç)
                safety_filter_level="block_only_high"
            )
            
            response = await self.client.aio.models.generate_images(
                model=model,
                prompt=prompt,
                config=config
            )
            
            if response.generated_images:
                image = response.generated_images[0]
                logger.info("Image generated successfully")
                return image.image_bytes
            
            logger.warning("Models returned no images")
            return None
            
        except Exception as e:
            logger.error(f"Error generating image: {e}")
            return None
